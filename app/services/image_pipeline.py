"""
Image Pipeline Service - FRIDA v0.5.2

Orquestra o pipeline completo de processamento de imagem:
1. Upload original ‚Üí bucket 'raw' ‚Üí type='original'
2. Segmenta√ß√£o (rembg) ‚Üí bucket 'segmented' ‚Üí type='segmented'
3. Composi√ß√£o ‚Üí bucket 'processed-images' ‚Üí type='processed'
4. Valida√ß√£o (husk_layer) ‚Üí quality_score

Todas as vers√µes s√£o registradas na tabela 'images'.
"""

import uuid
import threading
from datetime import datetime
from typing import Optional, Dict, Any
from dataclasses import dataclass, field
from io import BytesIO

from PIL import Image
from rembg import remove

from app.services.image_composer import image_composer
from app.services.husk_layer import husk_layer, QualityReport
from app.database import get_supabase_client, create_image
from app.config import settings


# =============================================================================
# Constants
# =============================================================================

BUCKETS = {
    "original": "raw",
    "segmented": "segmented",
    "processed": "processed-images"
}


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class PipelineResult:
    """
    Resultado do processamento completo do pipeline.

    Attributes:
        success: Se o pipeline completou com sucesso
        product_id: ID do produto processado
        images: Dict com info de cada imagem {type: {id, bucket, path, url}}
        quality_report: Relat√≥rio de qualidade (se processado)
        error: Mensagem de erro (se falhou)
    """
    success: bool
    product_id: str
    images: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    quality_report: Optional[QualityReport] = None
    error: Optional[str] = None

    def to_dict(self) -> dict:
        """Converte para dicion√°rio serializ√°vel."""
        return {
            "success": self.success,
            "product_id": self.product_id,
            "images": self.images,
            "quality_report": self.quality_report.to_dict() if self.quality_report else None,
            "error": self.error
        }


# =============================================================================
# Pipeline Class
# =============================================================================

class ImagePipelineSync:
    """
    Pipeline s√≠ncrono de processamento de imagem (MVP).

    Processa imagem em 3 est√°gios, salvando cada vers√£o no
    Supabase Storage e registrando na tabela images.
    """

    def __init__(self):
        """Inicializa o pipeline com thread-safe client loading."""
        self._client = None
        self._client_lock = threading.Lock()

    @property
    def client(self):
        """Thread-safe lazy load do Supabase client."""
        if self._client is None:
            with self._client_lock:
                # Double-check locking pattern
                if self._client is None:
                    self._client = get_supabase_client()
        return self._client
    
    # ==========================================================================
    # M√©todo Principal
    # ==========================================================================
    
    def process_image(
        self,
        image_bytes: bytes,
        product_id: str,
        user_id: str,
        filename: str = "image.png"
    ) -> PipelineResult:
        """
        Executa pipeline completo de processamento.

        Args:
            image_bytes: Bytes da imagem original
            product_id: UUID do produto
            user_id: UUID do usu√°rio
            filename: Nome original do arquivo

        Returns:
            PipelineResult com status e informa√ß√µes das imagens

        Note:
            Implementa rollback autom√°tico em caso de falha.
            Se qualquer etapa falhar, os arquivos j√° uploadados s√£o removidos.
        """
        result = PipelineResult(
            success=False,
            product_id=product_id,
            images={}
        )

        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")

        # Lista de arquivos uploadados para rollback em caso de erro
        uploaded_files: list[tuple[str, str]] = []  # [(bucket, path), ...]

        try:
            print(f"[PIPELINE] Iniciando processamento para produto {product_id}")

            # =================================================================
            # STAGE 0: Valida√ß√£o de Seguran√ßa (DoS Protection)
            # =================================================================
            print("[PIPELINE] Stage 0: Validando arquivo...")

            # Validar tamanho do arquivo
            file_size = len(image_bytes)
            if file_size > settings.MAX_FILE_SIZE_BYTES:
                size_mb = file_size / (1024 * 1024)
                raise ValueError(
                    f"Arquivo muito grande: {size_mb:.1f}MB. "
                    f"Limite: {settings.MAX_FILE_SIZE_MB}MB"
                )

            # Validar dimens√µes da imagem (previne memory exhaustion)
            with BytesIO(image_bytes) as img_buffer:
                with Image.open(img_buffer) as img:
                    width, height = img.size
                    max_dim = max(width, height)
                    if max_dim > settings.MAX_IMAGE_DIMENSION:
                        raise ValueError(
                            f"Imagem muito grande: {width}x{height}px. "
                            f"Dimens√£o m√°xima: {settings.MAX_IMAGE_DIMENSION}px"
                        )
                    print(f"[PIPELINE] ‚úì Valida√ß√£o OK: {file_size/1024:.1f}KB, {width}x{height}px")

            # =================================================================
            # STAGE 1: Upload Original
            # =================================================================
            print("[PIPELINE] Stage 1: Salvando original...")

            original_path = f"{product_id}/{timestamp}_original.png"
            original_url = self._upload_to_storage(
                bucket=BUCKETS["original"],
                path=original_path,
                data=image_bytes
            )

            if original_url:
                uploaded_files.append((BUCKETS["original"], original_path))
                original_record = self._create_image_record(
                    product_id=product_id,
                    image_type="original",
                    bucket=BUCKETS["original"],
                    path=original_path,
                    user_id=user_id
                )

                result.images["original"] = {
                    "id": original_record.get("id") if original_record else None,
                    "bucket": BUCKETS["original"],
                    "path": original_path,
                    "url": original_url
                }
                print(f"[PIPELINE] ‚úì Original salvo: {original_path}")

            # =================================================================
            # STAGE 2: Segmenta√ß√£o (rembg)
            # =================================================================
            print("[PIPELINE] Stage 2: Removendo fundo...")

            # Remover fundo usando rembg com tratamento de erro espec√≠fico
            try:
                segmented_bytes = remove(image_bytes)
            except MemoryError as e:
                raise RuntimeError(f"Mem√≥ria insuficiente para processar imagem: {e}")
            except Exception as e:
                # rembg pode falhar por v√°rios motivos: modelo n√£o carregado, imagem corrompida, etc.
                raise RuntimeError(f"Erro na segmenta√ß√£o (rembg): {e}")

            if not segmented_bytes:
                raise RuntimeError("Segmenta√ß√£o retornou imagem vazia")

            segmented_path = f"{product_id}/{timestamp}_segmented.png"
            segmented_url = self._upload_to_storage(
                bucket=BUCKETS["segmented"],
                path=segmented_path,
                data=segmented_bytes
            )

            if segmented_url:
                uploaded_files.append((BUCKETS["segmented"], segmented_path))
                segmented_record = self._create_image_record(
                    product_id=product_id,
                    image_type="segmented",
                    bucket=BUCKETS["segmented"],
                    path=segmented_path,
                    user_id=user_id
                )

                result.images["segmented"] = {
                    "id": segmented_record.get("id") if segmented_record else None,
                    "bucket": BUCKETS["segmented"],
                    "path": segmented_path,
                    "url": segmented_url
                }
                print(f"[PIPELINE] ‚úì Segmentado salvo: {segmented_path}")

            # =================================================================
            # STAGE 3: Composi√ß√£o (fundo branco)
            # =================================================================
            print("[PIPELINE] Stage 3: Compondo fundo branco...")

            # Compor com fundo branco usando image_composer
            processed_bytes = image_composer.compose_from_bytes(segmented_bytes)

            processed_path = f"{product_id}/{timestamp}_processed.png"
            processed_url = self._upload_to_storage(
                bucket=BUCKETS["processed"],
                path=processed_path,
                data=processed_bytes
            )

            if processed_url:
                uploaded_files.append((BUCKETS["processed"], processed_path))

            # =================================================================
            # STAGE 4: Valida√ß√£o de Qualidade
            # =================================================================
            print("[PIPELINE] Stage 4: Validando qualidade...")

            quality_report = husk_layer.validate_from_bytes(processed_bytes)
            result.quality_report = quality_report

            quality_score = quality_report.score if quality_report else None

            if processed_url:
                processed_record = self._create_image_record(
                    product_id=product_id,
                    image_type="processed",
                    bucket=BUCKETS["processed"],
                    path=processed_path,
                    user_id=user_id,
                    quality_score=quality_score
                )

                result.images["processed"] = {
                    "id": processed_record.get("id") if processed_record else None,
                    "bucket": BUCKETS["processed"],
                    "path": processed_path,
                    "url": processed_url,
                    "quality_score": quality_score
                }
                print(f"[PIPELINE] ‚úì Processado salvo: {processed_path}")
            
            # =================================================================
            # Sucesso
            # =================================================================
            result.success = True
            print(f"[PIPELINE] ‚úì Pipeline completo! Quality Score: {quality_score}/100")

        except Exception as e:
            error_msg = str(e)
            result.error = error_msg
            print(f"[PIPELINE] ‚ùå Erro: {error_msg}")

            # Rollback: remover arquivos j√° uploadados para evitar √≥rf√£os
            if uploaded_files:
                print(f"[PIPELINE] üîÑ Iniciando rollback de {len(uploaded_files)} arquivo(s)...")
                self._rollback_uploads(uploaded_files)

        return result
    
    # ==========================================================================
    # M√©todos Auxiliares
    # ==========================================================================

    def _rollback_uploads(self, uploaded_files: list[tuple[str, str]]) -> None:
        """
        Remove arquivos j√° uploadados em caso de falha no pipeline.

        Args:
            uploaded_files: Lista de tuplas (bucket, path) dos arquivos a remover

        Note:
            Erros de remo√ß√£o s√£o logados mas n√£o propagados,
            pois o pipeline j√° est√° em estado de erro.
        """
        for bucket, path in uploaded_files:
            try:
                self.client.storage.from_(bucket).remove([path])
                print(f"[PIPELINE] ‚úì Rollback: removido {bucket}/{path}")
            except Exception as e:
                # Log mas n√£o falha - j√° estamos em estado de erro
                print(f"[PIPELINE] ‚ö†Ô∏è Rollback falhou para {bucket}/{path}: {e}")

    def _upload_to_storage(
        self,
        bucket: str,
        path: str,
        data: bytes
    ) -> Optional[str]:
        """
        Upload de arquivo para Supabase Storage.
        
        Args:
            bucket: Nome do bucket
            path: Caminho do arquivo no bucket
            data: Bytes do arquivo
            
        Returns:
            URL p√∫blica do arquivo ou None se falhar
        """
        try:
            # Upload
            response = self.client.storage.from_(bucket).upload(
                path=path,
                file=data,
                file_options={"content-type": "image/png"}
            )
            
            # Gerar URL p√∫blica
            url_response = self.client.storage.from_(bucket).get_public_url(path)
            
            return url_response
            
        except Exception as e:
            print(f"[PIPELINE] ‚ö†Ô∏è Erro no upload ({bucket}/{path}): {str(e)}")
            return None
    
    def _create_image_record(
        self,
        product_id: str,
        image_type: str,
        bucket: str,
        path: str,
        user_id: str,
        quality_score: Optional[int] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Registra imagem na tabela images.
        
        Args:
            product_id: UUID do produto
            image_type: Tipo (original, segmented, processed)
            bucket: Nome do bucket
            path: Caminho no storage
            user_id: UUID do usu√°rio
            quality_score: Score de qualidade (0-100)
            
        Returns:
            Dict com dados do registro ou None se falhar
        """
        try:
            # Usar fun√ß√£o do database.py
            record = create_image(
                product_id=product_id,
                type=image_type,
                bucket=bucket,
                path=path,
                user_id=user_id
            )
            
            # Atualizar quality_score se fornecido
            if quality_score is not None and record:
                try:
                    self.client.table('images').update({
                        'quality_score': quality_score
                    }).eq('id', record['id']).execute()
                except Exception as e:
                    # Logar erro mas n√£o falhar o pipeline por causa do score
                    print(f"[PIPELINE] ‚ö†Ô∏è Erro ao atualizar quality_score: {e}")
            
            return record
            
        except Exception as e:
            print(f"[PIPELINE] ‚ö†Ô∏è Erro ao criar registro: {str(e)}")
            return None


# =============================================================================
# Singleton Export
# =============================================================================

image_pipeline_sync = ImagePipelineSync()
